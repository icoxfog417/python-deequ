{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example\n",
    "\n",
    "Here is a basic example of running a `VerificationSuite` with a couple `checks` and then filtering them based on their results. \n",
    "\n",
    "We'll start by creating a Spark session and a small sample dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please set env variable SPARK_VERSION\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/studio-lab-user/.conda/envs/deepqu/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/studio-lab-user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/studio-lab-user/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/home/studio-lab-user/.conda/envs/deepqu/lib/python3.10/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "com.amazon.deequ#deequ added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0929f323-3dcc-4685-a441-3af705fd0e2d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.amazon.deequ#deequ;1.2.2-spark-3.0 in central\n",
      "\tfound org.scalanlp#breeze_2.12;0.13.2 in central\n",
      "\tfound org.scalanlp#breeze-macros_2.12;0.13.2 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.1 in central\n",
      "\tfound com.github.fommil.netlib#core;1.1.2 in central\n",
      "\tfound net.sf.opencsv#opencsv;2.3 in central\n",
      "\tfound com.github.rwl#jtransforms;2.4.0 in central\n",
      "\tfound junit#junit;4.8.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.2 in central\n",
      "\tfound org.spire-math#spire_2.12;0.13.0 in central\n",
      "\tfound org.spire-math#spire-macros_2.12;0.13.0 in central\n",
      "\tfound org.typelevel#machinist_2.12;0.6.1 in central\n",
      "\tfound com.chuusai#shapeless_2.12;2.3.2 in central\n",
      "\tfound org.typelevel#macro-compat_2.12;1.1.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n",
      ":: resolution report :: resolve 507ms :: artifacts dl 16ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazon.deequ#deequ;1.2.2-spark-3.0 from central in [default]\n",
      "\tcom.chuusai#shapeless_2.12;2.3.2 from central in [default]\n",
      "\tcom.github.fommil.netlib#core;1.1.2 from central in [default]\n",
      "\tcom.github.rwl#jtransforms;2.4.0 from central in [default]\n",
      "\tjunit#junit;4.8.2 from central in [default]\n",
      "\tnet.sf.opencsv#opencsv;2.3 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.2 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.1 from central in [default]\n",
      "\torg.scalanlp#breeze-macros_2.12;0.13.2 from central in [default]\n",
      "\torg.scalanlp#breeze_2.12;0.13.2 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\torg.spire-math#spire-macros_2.12;0.13.0 from central in [default]\n",
      "\torg.spire-math#spire_2.12;0.13.0 from central in [default]\n",
      "\torg.typelevel#machinist_2.12;0.6.1 from central in [default]\n",
      "\torg.typelevel#macro-compat_2.12;1.1.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.scala-lang#scala-reflect;2.12.0 by [org.scala-lang#scala-reflect;2.12.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   16  |   0   |   0   |   1   ||   15  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0929f323-3dcc-4685-a441-3af705fd0e2d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 15 already retrieved (0kB/13ms)\n",
      "22/08/15 12:17:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/08/15 12:17:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pydeequ\n",
    "from pyspark.sql import Row, SparkSession\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.sparkContext.parallelize(\n",
    "    [Row(a=\"foo\", b=1, c=5), Row(a=\"bar\", b=2, c=6), Row(a=\"baz\", b=3, c=None)]\n",
    ").toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will be importing the necessary `PyDeequ` modules for running a VerificationSuite with Checks. We will be checking the following: \n",
    "\n",
    "- does `df` have a size of at least 3? \n",
    "- does the `b` column have a minimum value of 0? \n",
    "- is the `c` column complete? \n",
    "- is the `a` column unique? \n",
    "- are the values of `a` column contained in \"foo\", \"bar\", and \"baz\"? \n",
    "- are the values in `b` colum non-negative? \n",
    "\n",
    "Once these checks are run, we'll display out the dataframe to see the results!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Callback server started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+------------+--------------------+-----------------+--------------------+\n",
      "|           check|check_level|check_status|          constraint|constraint_status|  constraint_message|\n",
      "+----------------+-----------+------------+--------------------+-----------------+--------------------+\n",
      "|Integrity checks|      Error|       Error|SizeConstraint(Si...|          Success|                    |\n",
      "|Integrity checks|      Error|       Error|MinimumConstraint...|          Failure|Value: 1.0 does n...|\n",
      "|Integrity checks|      Error|       Error|CompletenessConst...|          Failure|Value: 0.66666666...|\n",
      "|Integrity checks|      Error|       Error|UniquenessConstra...|          Success|                    |\n",
      "|Integrity checks|      Error|       Error|ComplianceConstra...|          Success|                    |\n",
      "|Integrity checks|      Error|       Error|ComplianceConstra...|          Success|                    |\n",
      "+----------------+-----------+------------+--------------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.checks import *\n",
    "from pydeequ.verification import *\n",
    "\n",
    "\n",
    "check = Check(spark, CheckLevel.Error, \"Integrity checks\")\n",
    "\n",
    "checkResult = (\n",
    "    VerificationSuite(spark)\n",
    "    .onData(df)\n",
    "    .addCheck(\n",
    "        check.hasSize(lambda x: x >= 3)\n",
    "        .hasMin(\"b\", lambda x: x == 0)\n",
    "        .isComplete(\"c\")\n",
    "        .isUnique(\"a\")\n",
    "        .isContainedIn(\"a\", [\"foo\", \"bar\", \"baz\"])\n",
    "        .isNonNegative(\"b\")\n",
    "    )\n",
    "    .run()\n",
    ")\n",
    "\n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "checkResult_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's nice to see those as a dataframe, but we noticed a couple **Failures** in the `constraint_status` column! Let's filter them by accessing the `checkResults` property of our run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found errors in the data, the following constraints were not satisfied:\n",
      "\tMinimumConstraint(Minimum(b,None)) failed because: Value: 1.0 does not meet the constraint requirement!\n",
      "\tCompletenessConstraint(Completeness(c,None)) failed because: Value: 0.6666666666666666 does not meet the constraint requirement!\n"
     ]
    }
   ],
   "source": [
    "if checkResult.status == \"Success\":\n",
    "    print(\"The data passed the test, everything is fine!\")\n",
    "\n",
    "else:\n",
    "    print(\"We found errors in the data, the following constraints were not satisfied:\")\n",
    "\n",
    "    for check_json in checkResult.checkResults:\n",
    "        if check_json[\"constraint_status\"] != \"Success\":\n",
    "            print(\n",
    "                f\"\\t{check_json['constraint']} failed because: {check_json['constraint_message']}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepqu:Python",
   "language": "python",
   "name": "conda-env-deepqu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
